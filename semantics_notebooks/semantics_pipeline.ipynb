{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_df = pandas.concat([pandas.read_pickle('../news_df_norm1.pkl'), pandas.read_pickle('../news_df_norm2.pkl')])\n",
    "news_df = pandas.read_pickle('../news_df_norm1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unnecessary now\n",
    "#lucem_illud.setupStanfordNLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/Anaconda3-5.0.0.1-el7-x86_64/lib/python3.6/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "/software/Anaconda3-5.0.0.1-el7-x86_64/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['text'] = news_df['text'].apply(lambda x: re.sub(r'\\.\\s*\"\\s?', '\". ', x))\n",
    "news_df['text'] = news_df['text'].apply(lambda x: re.sub(r',\\s*\"\\s?', '\", ', x))\n",
    "# Substitutes .A with . A\n",
    "news_df['text'] = news_df['text'].apply(lambda x: re.sub(r'\\.(?=[A-Z])', '\", ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['tokenized_sentences'] = news_df['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_out = []\n",
    "oserrors = 0\n",
    "news_df['parse_sents'] = np.nan\n",
    "small_df = news_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parsed_list_or_nan(row, tokenized_sentences_col, id_col = None, error_list = None):\n",
    "    from numpy import nan\n",
    "    try:\n",
    "        print(\"{} {}\".format(row.name, row[id_col]))\n",
    "        return [list(parsed) for parsed in stanford.parser.parse_sents(row[tokenized_sentences_col])]\n",
    "    except ValueError as err:\n",
    "        print(row[id_col])\n",
    "        print(err)\n",
    "        if error_list:\n",
    "            error_list.append((row[id_col], \"{}\".format(err)))\n",
    "        return nan\n",
    "    except OSError as err:\n",
    "        print(row[id_col])\n",
    "        print(err)\n",
    "        if error_list:\n",
    "            error_list.append((row[id_col], \"{}\".format(err)))\n",
    "        return nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1417 ./data/CH/CH4_59.html\n",
      "1964 ./data/IN/IN3_42.html\n",
      "642 ./data/AU/AUS3_70.html\n",
      "1532 ./data/CH/CH4_42.html\n",
      "973 ./data/AU/AUS2_67.html\n",
      "1693 ./data/CH/CH2_3.html\n",
      "608 ./data/AU/AUS5_36.html\n",
      "2065 ./data/IN/IN6_6.html\n",
      "807 ./data/AU/AUS_16.html\n",
      "754 ./data/AU/AU6_45.html\n"
     ]
    }
   ],
   "source": [
    "small_df['parse_sents'] = small_df.apply(lambda x: set_parsed_list_or_nan(x, 'tokenized_sentences', id_col='filename', error_list=errors_out), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "extract_direct_object(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       S                            \n",
      "      _________________|_____                        \n",
      "     |                       VP                     \n",
      "     |             __________|___                    \n",
      "     |            |             ADJP                \n",
      "     |            |     _________|____               \n",
      "     |            |    |              S             \n",
      "     |            |    |              |              \n",
      "     |            |    |              VP            \n",
      "     |            |    |      ________|___           \n",
      "     |            |    |     |            VP        \n",
      "     |            |    |     |    ________|___       \n",
      "     NP           |    |     |   |            NP    \n",
      "  ___|_____       |    |     |   |         ___|___   \n",
      " DT        NN    VBD   JJ    TO  VB      PRP      ''\n",
      " |         |      |    |     |   |        |       |  \n",
      "the     hospital was unable  to pay      him      ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at 14\n",
    "experiment = small_df.iloc[0].parse_sents[25][0][0][1][2][1][1][2][1]\n",
    "experiment.pretty_print()\n",
    "#print(get_SVOs_in_sentence_tree(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        VP                                                \n",
      "    ____________________________________________________|____                                              \n",
      "   |                                                         NP                                           \n",
      "   |            _____________________________________________|____________________                         \n",
      "   |           |             |                    |               |              SBAR                     \n",
      "   |           |             |                    |               |     __________|_____                   \n",
      "   |           |             |                    |               |    |                S                 \n",
      "   |           |             |                    |               |    |           _____|_________         \n",
      "   |           |             |                    |               |    |          |               VP      \n",
      "   |           |             |                    |               |    |          |            ___|____    \n",
      "   |           NP            |                    NP              |  WHADVP       NP          |        VP \n",
      "   |       ____|______       |      ______________|__________     |    |      ____|_____      |        |   \n",
      "  VBN     CD         NNS     ,     JJ      NN    NNS    CC  NNS   ,   WRB    NN   CC   NNS   VBP      VBN \n",
      "   |      |           |      |     |       |      |     |    |    |    |     |    |     |     |        |   \n",
      "crippled four     provinces  ,  damaging water systems and farms  ,  where  rice and  fruits are     grown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment[0,0,1,1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 S                                                                                  \n",
      "                   ______________________________________________|________________________________________________________________________________   \n",
      "                  |                      VP                                                                                                       | \n",
      "                  |                   ___|_____                                                                                                   |  \n",
      "                  |                  |         VP                                                                                                 | \n",
      "                  |                  |    _____|____                                                                                              |  \n",
      "                  |                  |   |          VP                                                                                            | \n",
      "                  |                  |   |      ____|__________________                                                                           |  \n",
      "                  |                  |   |     |        |             SBAR                                                                        | \n",
      "                  |                  |   |     |        |         _____|____                                                                      |  \n",
      "                  |                  |   |     |        |        |          S                                                                     | \n",
      "                  |                  |   |     |        |        |      ____|________                                                             |  \n",
      "                  |                  |   |     |        |        |     |             VP                                                           | \n",
      "                  |                  |   |     |        |        |     |     ________|___________________________                                 |  \n",
      "                  NP                 |   |     |        |        |     |    |                                    VP                               | \n",
      "        __________|_______           |   |     |        |        |     |    |         ___________________________|____________                    |  \n",
      "       |                  PP         |   |     |        |        |     |    |        |                    |                   PP                  | \n",
      "       |               ___|____      |   |     |        |        |     |    |        |                    |              _____|____               |  \n",
      "       NP             |        NP    |   |     |        NP     WHADVP  NP   |        |                    NP            |          NP             | \n",
      "   ____|____          |        |     |   |     |     ___|___     |     |    |        |            ________|______       |      ____|______        |  \n",
      "  DT        NN        IN      NNP   VBZ VBN   VBN   DT      NN  WRB   PRP   MD       VB          JJ             NNS     IN   PRP$        NNS      . \n",
      "  |         |         |        |     |   |     |    |       |    |     |    |        |           |               |      |     |           |       |  \n",
      "Every     parish      in     Mumbai has been given  a      day  when  they will incorporate environment-     practices into their     activities  . \n",
      "                                                                                               saving                                               \n",
      "\n",
      "      S                                                                   \n",
      "  ____|________                                                            \n",
      " |             VP                                                         \n",
      " |     ________|___________________________                                \n",
      " |    |                                    VP                             \n",
      " |    |         ___________________________|____________                   \n",
      " |    |        |                    |                   PP                \n",
      " |    |        |                    |              _____|____              \n",
      " NP   |        |                    NP            |          NP           \n",
      " |    |        |            ________|______       |      ____|______       \n",
      "PRP   MD       VB          JJ             NNS     IN   PRP$        NNS    \n",
      " |    |        |           |               |      |     |           |      \n",
      "they will incorporate environment-     practices into their     activities\n",
      "                         saving                                           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in experiment[0].subtrees():\n",
    "    if a.label()=='S':\n",
    "        a.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun(tree):\n",
    "    if not tree.label().startswith('N'):\n",
    "        return ''\n",
    "    result = ''\n",
    "    for child in tree:\n",
    "        if child.label() == 'NP':\n",
    "            result += extract_noun(child)\n",
    "        elif child.label().startswith('NN') or \\\n",
    "            child.label() == 'PRP':\n",
    "            result += child[0] + ' '\n",
    "        elif child.label() == ',':\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def extract_verb(tree, stem_verb=True, lemmer=None):\n",
    "    if not tree.label().startswith('V'):\n",
    "        return ''\n",
    "    lemmer = nltk.stem.WordNetLemmatizer()\n",
    "    result = ''\n",
    "    for child in tree:\n",
    "        if child.label() == 'VP':\n",
    "            result += extract_verb(child, stem_verb=stem_verb, lemmer=lemmer)\n",
    "        elif child.label().startswith('VB'):\n",
    "            result += lemmer.lemmatize(child[0], pos='v') + ' '\n",
    "    return result\n",
    "\n",
    "def extract_direct_object(tree):\n",
    "    #pdb.set_trace()\n",
    "    if not tree.label().startswith('VP'):\n",
    "        return ''\n",
    "    for child in tree:\n",
    "        if child.label() == 'NP':\n",
    "            return extract_noun(child)\n",
    "        elif child.label() == 'PP':\n",
    "            for subchild in child:\n",
    "                if subchild.label() == 'NP':\n",
    "                    return extract_noun(subchild)\n",
    "    for child in tree:\n",
    "        if child.label() == 'VP':\n",
    "            return extract_direct_object(child)\n",
    "    return ''\n",
    "\n",
    "def extract_SVO(tree, last_noun = True):\n",
    "    subject = verb = objec = ''\n",
    "    if not tree.label() == 'S':\n",
    "        return None\n",
    "    for child in tree:\n",
    "        if child.label() == 'NP':\n",
    "            subject = extract_noun(child)\n",
    "        elif child.label() == 'VP':\n",
    "            verb = condense_verbs(extract_verb(child))\n",
    "            objec = extract_direct_object(child)\n",
    "    if last_noun:\n",
    "        subject = subject.strip().split(' ')[-1]\n",
    "        objec = objec.strip().split(' ')[-1]\n",
    "    return (subject, verb, objec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hide'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemming = nltk.stem.WordNetLemmatizer()\n",
    "lemming.lemmatize('hidden', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SVOs_in_sentence_tree(tree):\n",
    "    result = []\n",
    "    for subt in tree.subtrees():\n",
    "        if subt.label()=='S':\n",
    "            result.append(extract_SVO(subt, last_noun=True))\n",
    "    return result\n",
    "\n",
    "def condense_verbs(verbs):\n",
    "    vblist = verbs.split()\n",
    "    if len(vblist) < 2:\n",
    "        return verbs\n",
    "    aux= ['have', 'has', 'had', 'been', 'are', 'is', 'be', 'am', 'does', 'did', 'was', 'being', 'having']\n",
    "    return \" \".join([vb for vb in vblist if vb not in aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = sampled_df\n",
    "svo_big_list = []\n",
    "for ix, row in small_df.iterrows():\n",
    "    for sent_tree in row.parse_sents:\n",
    "        for svo in get_SVOs_in_sentence_tree(sent_tree[0]):\n",
    "            if svo[0] != '' : \n",
    "                svo_big_list.append({'filename': row['filename'],\n",
    "                                'country': row['country'],\n",
    "                                'subject': svo[0],\n",
    "                                'verb': svo[1],\n",
    "                                'object': svo[2]})\n",
    "small_df['svos'] = small_df['parse_sents'].apply(lambda x: [get_SVOs_in_sentence_tree(i[0]) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Angolans cast their ballots Wednesday in an election marking the end of President Jose Eduardo Dos Santos's 38-year reign, with his MPLA party set to retain power despite an economic crisis.  The MPLA, which has ruled since Angola's independence from Portugal in 1975, is expected to defeat opposition parties, which are stifled by Dos Santos's authoritarian regime.  Dos Santos's unexpected retirement — reportedly prompted by poor health — has triggered the biggest political transition in decades for Angola, a leading oil exporter in Africa.  However, his chosen successor is Defence Minister Joao Lourenco, a loyalist expected to avoid immediate change in a government often criticised for corruption and its failure to tackle dire poverty\". My mission will be to revive the economy\", Lourenco told reporters in the capital Luanda on the eve of the vote\". If I succeed, I would like to be recognised in history as the man of Angola's economic miracle\".  Dos Santos's long reign has seen the end of Angola's bloody civil war that lasted from 1975 to 2002, and a post-war investment boom as the country exploited its oil reserves.  But the flood of money brought little benefit to Angola's poor, and government spending collapsed when oil prices fell in 2014.  Inflation hit 40 per cent at the end of 2016, when annual growth was less than one per cent.  TRANSITIONAL SUCCESSOR  Lourenco, 63, vowed to boost foreign investment and said the MPLA (People's Movement for the Liberation of Angola) would be carried to election victory by \"great popular support\".  AFP reporters witnessed a slow start to voting at one station in Luanda where Dos Santos and Lourenco are scheduled to cast their ballots later Wednesday.  At a weekend rally in front of thousands of MPLA supporters, Dos Santos, a frail-looking 74, made a brief appearance to endorse Lourenco\". Dos Santos brought forward his departure to after these elections due to his deteriorating health\", Alex Vines, of the Chatham House think tank, told AFP\". Lourenco is an ideal transitional successor to Dos Santos. He is respected by the military and has not lived a flamboyant lifestyle of many others\".  ILL HEALTH  Dos Santos has been dogged by reports of illness. His regular visits to Spain for \"private\" reasons fuelled criticism that the state of his health was being hidden from ordinary Angolans.  Earlier this year, his daughter Isabel — who has become a billionaire and Africa's richest businesswoman under his rule — was forced to deny rumours he had died in Spain.  In the face of ruthless security force crackdowns and a biased state-run media, the opposition parties — led by Unita and Casa-CE — have sought to tap into public anger at the government\". You who are suffering, you who are in poverty, without electricity, without jobs or nothing to eat — change is now\", Isaias Samakuva, the Unita leader told supporters on the campaign trail.  Samakuva, 71, took over Unita after long time rebel leader Jonas Savimbi was killed in 2002, a death that marked the beginning of the end of the civil war.  APPALLING HUMAN RIGHTS RECORD  Dissent has often been dangerous under Dos Santos, who has been a secretive but inescapable presence in Angolan life for decades.  Angola's next leader \"must guide the country out of the spiral of oppression\", rights group Amnesty said in a statement\". Dos Santos' presidency is marked by his appalling human rights record. For decades, Angolans have lived in a climate of fear in which speaking out was met with intimidation (and) imprisonment\".  Mateos Simon, 28, a former nurse, told AFP that he lost his job because the hospital was unable to pay him\". I live in a house where there is no water, no electricity\", he said\". The MPLA does nothing for us. Things have to change, now\".  Polls are due to close at 6pm (1700 GMT).\n",
      "[[('Angolans', 'cast ', 'ballots'), ('', 'retain ', 'power')], [('MPLA', 'expect', ''), ('', 'rule', 'independence'), ('', 'defeat ', 'parties'), ('', 'stifle', 'regime')], [('—', 'trigger', 'transition')], [('successor', 'be ', 'Lourenco'), ('', 'avoid ', 'change'), ('', 'tackle ', 'poverty')], [('Lourenco', 'tell ', 'reporters'), ('mission', 'be ', ''), ('', 'revive ', 'economy')], [('I', 'like ', 'man'), ('I', 'succeed ', ''), ('', 'recognise', 'history')], [('reign', 'see', 'end'), ('', 'last ', '')], [('', '', ''), ('flood', 'bring ', 'benefit'), ('spending', 'collapse ', ''), ('prices', 'fell ', '')], [('Inflation', 'hit ', ''), ('growth', 'be ', '')], [('Lourenco', 'vow say', ''), ('', 'boost ', 'investment'), ('MPLA', 'carry', 'victory')], [('reporters', 'witness ', 'start'), ('Lourenco', 'schedule', ''), ('', 'cast ', 'ballots')], [('Santos', 'make ', 'appearance'), ('', 'endorse ', 'Lourenco')], [('Vines', 'tell ', 'AFP'), ('Santos', 'bring ', 'departure')], [('Lourenco', 'be ', 'successor')], [('He', 'live', '')], [('Santos', 'dog', 'reports')], [('visits', 'fuel ', 'criticism'), ('state', 'hide', 'Angolans')], [('—', 'force', ''), ('', 'become', 'businesswoman'), ('', 'deny ', 'rumours'), ('he', 'die', 'Spain')], [('—', 'seek', 'government'), ('', 'tap ', 'anger')], [('You', 'be ', ''), ('', 'suffer', ''), ('', 'be ', ''), ('', 'eat ', 'change'), ('Samakuva', 'tell ', 'supporters')], [('Samakuva', 'take ', 'Unita'), ('Savimbi', 'kill', ''), ('', 'mark ', 'beginning')], [('Dissent', '', ''), ('', '', 'presence')], [('group', 'say ', 'statement'), ('leader', 'guide ', 'country')], [('presidency', 'mark', 'record')], [('Angolans', 'live', 'climate'), ('', 'meet', 'imprisonment'), ('', 'speak ', '')], [('Simon', 'tell ', 'AFP'), ('he', 'lose ', 'job'), ('hospital', 'be ', ''), ('', 'pay ', 'him')], [('he', 'say ', ''), ('I', 'live ', 'house'), ('', 'be ', 'water')], [('MPLA', 'do ', 'nothing')], [('Things', 'have ', ''), ('', 'change ', '')], [('Polls', 'be ', ''), ('', 'close ', '6pm')]]\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "print(small_df.iloc[ix].text)\n",
    "print(small_df.iloc[ix].svos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_df = pandas.DataFrame(svo_big_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45048"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>filename</th>\n",
       "      <th>object</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>ballots</td>\n",
       "      <td>Angolans</td>\n",
       "      <td>cast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>MPLA</td>\n",
       "      <td>expect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>transition</td>\n",
       "      <td>—</td>\n",
       "      <td>trigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>Lourenco</td>\n",
       "      <td>successor</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>reporters</td>\n",
       "      <td>Lourenco</td>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>mission</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>man</td>\n",
       "      <td>I</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "      <td>succeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>end</td>\n",
       "      <td>reign</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>benefit</td>\n",
       "      <td>flood</td>\n",
       "      <td>bring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>spending</td>\n",
       "      <td>collapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>prices</td>\n",
       "      <td>fell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>Inflation</td>\n",
       "      <td>hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>growth</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>Lourenco</td>\n",
       "      <td>vow say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>victory</td>\n",
       "      <td>MPLA</td>\n",
       "      <td>carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>start</td>\n",
       "      <td>reporters</td>\n",
       "      <td>witness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>Lourenco</td>\n",
       "      <td>schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>appearance</td>\n",
       "      <td>Santos</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>AFP</td>\n",
       "      <td>Vines</td>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>departure</td>\n",
       "      <td>Santos</td>\n",
       "      <td>bring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>successor</td>\n",
       "      <td>Lourenco</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>He</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>reports</td>\n",
       "      <td>Santos</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>criticism</td>\n",
       "      <td>visits</td>\n",
       "      <td>fuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>Angolans</td>\n",
       "      <td>state</td>\n",
       "      <td>hide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>—</td>\n",
       "      <td>force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>Spain</td>\n",
       "      <td>he</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td>government</td>\n",
       "      <td>—</td>\n",
       "      <td>seek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KE</td>\n",
       "      <td>./data/KE/KE5_39.html</td>\n",
       "      <td></td>\n",
       "      <td>You</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45018</th>\n",
       "      <td>IN</td>\n",
       "      <td>./data/IN/IN5_44.html</td>\n",
       "      <td></td>\n",
       "      <td>administration</td>\n",
       "      <td>renege</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45019</th>\n",
       "      <td>IN</td>\n",
       "      <td>./data/IN/IN5_44.html</td>\n",
       "      <td></td>\n",
       "      <td>community</td>\n",
       "      <td>look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45020</th>\n",
       "      <td>IN</td>\n",
       "      <td>./data/IN/IN5_44.html</td>\n",
       "      <td>fund</td>\n",
       "      <td>Obama</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45021</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>plant</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45022</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>plant</td>\n",
       "      <td>officially</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45023</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>heat</td>\n",
       "      <td>plant</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45024</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>electricity</td>\n",
       "      <td>It</td>\n",
       "      <td>produce say improve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45025</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>solution</td>\n",
       "      <td>technology</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45026</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>reduction</td>\n",
       "      <td>investment</td>\n",
       "      <td>bring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45027</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>Zulkifli</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45028</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>’</td>\n",
       "      <td>facility</td>\n",
       "      <td>contribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45029</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>pace</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45030</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>China</td>\n",
       "      <td>He</td>\n",
       "      <td>cite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45031</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>Masagos</td>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45032</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>bonus</td>\n",
       "      <td>world</td>\n",
       "      <td>reap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45033</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>half</td>\n",
       "      <td>China</td>\n",
       "      <td>account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45034</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>Masagos</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45035</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>China</td>\n",
       "      <td>invest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45036</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>it</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45037</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>tax</td>\n",
       "      <td>speech</td>\n",
       "      <td>come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45038</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>Revenue</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45039</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>initiatives</td>\n",
       "      <td>industries</td>\n",
       "      <td>implement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45040</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>We</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45041</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>economy</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45042</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>it</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45043</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>companies</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45044</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>he</td>\n",
       "      <td>add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45045</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>place</td>\n",
       "      <td>we</td>\n",
       "      <td>put</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45046</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td></td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45047</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME9_0.html</td>\n",
       "      <td>facilities</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45048 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country               filename       object         subject  \\\n",
       "0          KE  ./data/KE/KE5_39.html      ballots        Angolans   \n",
       "1          KE  ./data/KE/KE5_39.html                         MPLA   \n",
       "2          KE  ./data/KE/KE5_39.html   transition               —   \n",
       "3          KE  ./data/KE/KE5_39.html     Lourenco       successor   \n",
       "4          KE  ./data/KE/KE5_39.html    reporters        Lourenco   \n",
       "5          KE  ./data/KE/KE5_39.html                      mission   \n",
       "6          KE  ./data/KE/KE5_39.html          man               I   \n",
       "7          KE  ./data/KE/KE5_39.html                            I   \n",
       "8          KE  ./data/KE/KE5_39.html          end           reign   \n",
       "9          KE  ./data/KE/KE5_39.html      benefit           flood   \n",
       "10         KE  ./data/KE/KE5_39.html                     spending   \n",
       "11         KE  ./data/KE/KE5_39.html                       prices   \n",
       "12         KE  ./data/KE/KE5_39.html                    Inflation   \n",
       "13         KE  ./data/KE/KE5_39.html                       growth   \n",
       "14         KE  ./data/KE/KE5_39.html                     Lourenco   \n",
       "15         KE  ./data/KE/KE5_39.html      victory            MPLA   \n",
       "16         KE  ./data/KE/KE5_39.html        start       reporters   \n",
       "17         KE  ./data/KE/KE5_39.html                     Lourenco   \n",
       "18         KE  ./data/KE/KE5_39.html   appearance          Santos   \n",
       "19         KE  ./data/KE/KE5_39.html          AFP           Vines   \n",
       "20         KE  ./data/KE/KE5_39.html    departure          Santos   \n",
       "21         KE  ./data/KE/KE5_39.html    successor        Lourenco   \n",
       "22         KE  ./data/KE/KE5_39.html                           He   \n",
       "23         KE  ./data/KE/KE5_39.html      reports          Santos   \n",
       "24         KE  ./data/KE/KE5_39.html    criticism          visits   \n",
       "25         KE  ./data/KE/KE5_39.html     Angolans           state   \n",
       "26         KE  ./data/KE/KE5_39.html                            —   \n",
       "27         KE  ./data/KE/KE5_39.html        Spain              he   \n",
       "28         KE  ./data/KE/KE5_39.html   government               —   \n",
       "29         KE  ./data/KE/KE5_39.html                          You   \n",
       "...       ...                    ...          ...             ...   \n",
       "45018      IN  ./data/IN/IN5_44.html               administration   \n",
       "45019      IN  ./data/IN/IN5_44.html                    community   \n",
       "45020      IN  ./data/IN/IN5_44.html         fund           Obama   \n",
       "45021      ME   ./data/ME/ME9_0.html        plant      ExxonMobil   \n",
       "45022      ME   ./data/ME/ME9_0.html        plant      officially   \n",
       "45023      ME   ./data/ME/ME9_0.html         heat           plant   \n",
       "45024      ME   ./data/ME/ME9_0.html  electricity              It   \n",
       "45025      ME   ./data/ME/ME9_0.html     solution      technology   \n",
       "45026      ME   ./data/ME/ME9_0.html    reduction      investment   \n",
       "45027      ME   ./data/ME/ME9_0.html                     Zulkifli   \n",
       "45028      ME   ./data/ME/ME9_0.html            ’        facility   \n",
       "45029      ME   ./data/ME/ME9_0.html         pace       Singapore   \n",
       "45030      ME   ./data/ME/ME9_0.html        China              He   \n",
       "45031      ME   ./data/ME/ME9_0.html                      Masagos   \n",
       "45032      ME   ./data/ME/ME9_0.html        bonus           world   \n",
       "45033      ME   ./data/ME/ME9_0.html         half           China   \n",
       "45034      ME   ./data/ME/ME9_0.html                      Masagos   \n",
       "45035      ME   ./data/ME/ME9_0.html                        China   \n",
       "45036      ME   ./data/ME/ME9_0.html                           it   \n",
       "45037      ME   ./data/ME/ME9_0.html          tax          speech   \n",
       "45038      ME   ./data/ME/ME9_0.html                      Revenue   \n",
       "45039      ME   ./data/ME/ME9_0.html  initiatives      industries   \n",
       "45040      ME   ./data/ME/ME9_0.html                           We   \n",
       "45041      ME   ./data/ME/ME9_0.html      economy       Singapore   \n",
       "45042      ME   ./data/ME/ME9_0.html                           it   \n",
       "45043      ME   ./data/ME/ME9_0.html                    companies   \n",
       "45044      ME   ./data/ME/ME9_0.html                           he   \n",
       "45045      ME   ./data/ME/ME9_0.html        place              we   \n",
       "45046      ME   ./data/ME/ME9_0.html                   ExxonMobil   \n",
       "45047      ME   ./data/ME/ME9_0.html   facilities         Pacific   \n",
       "\n",
       "                      verb  \n",
       "0                    cast   \n",
       "1                   expect  \n",
       "2                  trigger  \n",
       "3                      be   \n",
       "4                    tell   \n",
       "5                      be   \n",
       "6                    like   \n",
       "7                 succeed   \n",
       "8                      see  \n",
       "9                   bring   \n",
       "10               collapse   \n",
       "11                   fell   \n",
       "12                    hit   \n",
       "13                     be   \n",
       "14                 vow say  \n",
       "15                   carry  \n",
       "16                witness   \n",
       "17                schedule  \n",
       "18                   make   \n",
       "19                   tell   \n",
       "20                  bring   \n",
       "21                     be   \n",
       "22                    live  \n",
       "23                     dog  \n",
       "24                   fuel   \n",
       "25                    hide  \n",
       "26                   force  \n",
       "27                     die  \n",
       "28                    seek  \n",
       "29                     be   \n",
       "...                    ...  \n",
       "45018              renege   \n",
       "45019                 look  \n",
       "45020                 make  \n",
       "45021                open   \n",
       "45022                open   \n",
       "45023                 use   \n",
       "45024  produce say improve  \n",
       "45025                  be   \n",
       "45026               bring   \n",
       "45027                 say   \n",
       "45028          contribute   \n",
       "45029                keep   \n",
       "45030                cite   \n",
       "45031               point   \n",
       "45032                 reap  \n",
       "45033              account  \n",
       "45034                 say   \n",
       "45035              invest   \n",
       "45036                  set  \n",
       "45037                come   \n",
       "45038                  go   \n",
       "45039           implement   \n",
       "45040                  be   \n",
       "45041                  be   \n",
       "45042                  be   \n",
       "45043                stay   \n",
       "45044                 add   \n",
       "45045                  put  \n",
       "45046                  be   \n",
       "45047                have   \n",
       "\n",
       "[45048 rows x 5 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>filename</th>\n",
       "      <th>object</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2334</td>\n",
       "      <td>2334</td>\n",
       "      <td>2334</td>\n",
       "      <td>2334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>2043</td>\n",
       "      <td>2043</td>\n",
       "      <td>2043</td>\n",
       "      <td>2043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>1163</td>\n",
       "      <td>1163</td>\n",
       "      <td>1163</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It</th>\n",
       "      <td>1097</td>\n",
       "      <td>1097</td>\n",
       "      <td>1097</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We</th>\n",
       "      <td>827</td>\n",
       "      <td>827</td>\n",
       "      <td>827</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>653</td>\n",
       "      <td>653</td>\n",
       "      <td>653</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He</th>\n",
       "      <td>638</td>\n",
       "      <td>638</td>\n",
       "      <td>638</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>531</td>\n",
       "      <td>531</td>\n",
       "      <td>531</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>340</td>\n",
       "      <td>340</td>\n",
       "      <td>340</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countries</th>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>They</th>\n",
       "      <td>287</td>\n",
       "      <td>287</td>\n",
       "      <td>287</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>”</th>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientists</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>She</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xi</th>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summers</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sud</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub-nationalism</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sturgess</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stuparich</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Struggles</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strike</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stressing</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgeries</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Susantono</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sussex</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwo-Oguntuase</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taalas</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOURISM</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TERRORIST</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Systems</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>System</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Syrians</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symptoms</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sylwester</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swati</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swaminathan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>…</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7157 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country  filename  object  verb\n",
       "subject                                         \n",
       "it                  2334      2334    2334  2334\n",
       "we                  2043      2043    2043  2043\n",
       "he                  1463      1463    1463  1463\n",
       "I                   1444      1444    1444  1444\n",
       "they                1163      1163    1163  1163\n",
       "It                  1097      1097    1097  1097\n",
       "We                   827       827     827   827\n",
       "’                    784       784     784   784\n",
       "change               653       653     653   653\n",
       "He                   638       638     638   638\n",
       "you                  621       621     621   621\n",
       "Trump                531       531     531   531\n",
       "China                395       395     395   395\n",
       "people               340       340     340   340\n",
       "she                  333       333     333   333\n",
       "countries            314       314     314   314\n",
       "They                 287       287     287   287\n",
       "US                   246       246     246   246\n",
       "report               220       220     220   220\n",
       "government           214       214     214   214\n",
       "world                181       181     181   181\n",
       "”                    173       173     173   173\n",
       "India                162       162     162   162\n",
       "scientists           151       151     151   151\n",
       "climate              134       134     134   134\n",
       "She                  132       132     132   132\n",
       "t                    130       130     130   130\n",
       "country              130       130     130   130\n",
       "them                 127       127     127   127\n",
       "Xi                   127       127     127   127\n",
       "...                  ...       ...     ...   ...\n",
       "Summers                1         1       1     1\n",
       "Sud                    1         1       1     1\n",
       "Talal                  1         1       1     1\n",
       "Success                1         1       1     1\n",
       "Sub-nationalism        1         1       1     1\n",
       "Sturgess               1         1       1     1\n",
       "Stuparich              1         1       1     1\n",
       "Struggles              1         1       1     1\n",
       "Strike                 1         1       1     1\n",
       "Stressing              1         1       1     1\n",
       "Surface                1         1       1     1\n",
       "Surgeries              1         1       1     1\n",
       "Susantono              1         1       1     1\n",
       "Sussex                 1         1       1     1\n",
       "Taiwo-Oguntuase        1         1       1     1\n",
       "Taiwan                 1         1       1     1\n",
       "Taalas                 1         1       1     1\n",
       "TRC                    1         1       1     1\n",
       "TOURISM                1         1       1     1\n",
       "TERRORIST              1         1       1     1\n",
       "TCA                    1         1       1     1\n",
       "T                      1         1       1     1\n",
       "Systems                1         1       1     1\n",
       "System                 1         1       1     1\n",
       "Syrians                1         1       1     1\n",
       "Symptoms               1         1       1     1\n",
       "Sylwester              1         1       1     1\n",
       "Swati                  1         1       1     1\n",
       "Swaminathan            1         1       1     1\n",
       "…                      1         1       1     1\n",
       "\n",
       "[7157 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svo_df.groupby(by='subject').count().sort_values(by='verb', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pandas.read_pickle('sampletrees3k.pkl')#'sampletrees1k.pkl')\n",
    "sampled_df.dropna(inplace=True)\n",
    "svo_big_list = []\n",
    "import math\n",
    "for ix, row in sampled_df.iterrows():\n",
    "    for sent_tree in row['parse_sents']:\n",
    "        for svo in get_SVOs_in_sentence_tree(sent_tree[0]):\n",
    "            if svo[0] != '' : \n",
    "                svo_big_list.append({'filename': row['filename'],\n",
    "                                'country': row['country'],\n",
    "                                'subject': svo[0],\n",
    "                                'verb': svo[1],\n",
    "                                'object': svo[2]})\n",
    "svo_df = pandas.DataFrame(svo_big_list)\n",
    "#svo_df.to_pickle('svo_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>filename</th>\n",
       "      <th>object</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>networks</td>\n",
       "      <td>vision</td>\n",
       "      <td>evoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>regions</td>\n",
       "      <td>include</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>probability</td>\n",
       "      <td>dismiss anticipate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>series</td>\n",
       "      <td>situations</td>\n",
       "      <td>arise do occur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>framework</td>\n",
       "      <td>Goals</td>\n",
       "      <td>serve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>key</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>they</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>part</td>\n",
       "      <td>management</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>conflicts</td>\n",
       "      <td>communities</td>\n",
       "      <td>resolve become exacerbate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>they</td>\n",
       "      <td>arise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>stage</td>\n",
       "      <td>Conflicts</td>\n",
       "      <td>mitigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>they</td>\n",
       "      <td>escalate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>Dialogues</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>causes</td>\n",
       "      <td>parties</td>\n",
       "      <td>find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>access</td>\n",
       "      <td>cause</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>changes</td>\n",
       "      <td>effects</td>\n",
       "      <td>cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>mitigation</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>aspects</td>\n",
       "      <td>attention</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>potential</td>\n",
       "      <td>prevent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>cooperation</td>\n",
       "      <td>Institute</td>\n",
       "      <td>enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>it</td>\n",
       "      <td>promote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>Goals</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>discussions</td>\n",
       "      <td>Dialogues</td>\n",
       "      <td>promote build sustain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td></td>\n",
       "      <td>Dialogues</td>\n",
       "      <td>aim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>Director</td>\n",
       "      <td>Veres</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CH</td>\n",
       "      <td>./data/CH/CH2_38.html</td>\n",
       "      <td>director</td>\n",
       "      <td>Brahm</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>UK</td>\n",
       "      <td>./data/UK/UK6_7.html</td>\n",
       "      <td></td>\n",
       "      <td>It</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UK</td>\n",
       "      <td>./data/UK/UK6_7.html</td>\n",
       "      <td>Islands</td>\n",
       "      <td>Sura</td>\n",
       "      <td>fly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UK</td>\n",
       "      <td>./data/UK/UK6_7.html</td>\n",
       "      <td>enormity</td>\n",
       "      <td>she</td>\n",
       "      <td>appreciate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UK</td>\n",
       "      <td>./data/UK/UK6_7.html</td>\n",
       "      <td></td>\n",
       "      <td>she</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136610</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME7.1 (44).html</td>\n",
       "      <td>plans</td>\n",
       "      <td>’</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136611</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME7.1 (44).html</td>\n",
       "      <td>Center</td>\n",
       "      <td>We</td>\n",
       "      <td>open target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136612</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME7.1 (44).html</td>\n",
       "      <td></td>\n",
       "      <td>It</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136613</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME7.1 (44).html</td>\n",
       "      <td></td>\n",
       "      <td>we</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136614</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME7.1 (44).html</td>\n",
       "      <td>cranes</td>\n",
       "      <td>we</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136615</th>\n",
       "      <td>ME</td>\n",
       "      <td>./data/ME/ME7.1 (44).html</td>\n",
       "      <td></td>\n",
       "      <td>we</td>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136616</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>Council</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136617</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>discussions</td>\n",
       "      <td>council</td>\n",
       "      <td>benefit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136618</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>steps</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136619</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>response</td>\n",
       "      <td>debate</td>\n",
       "      <td>dominate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136620</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>objections</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136621</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>it</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136622</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>sceptics</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136623</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>we</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136624</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>nothing</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136625</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>pollution</td>\n",
       "      <td>they</td>\n",
       "      <td>'re support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136626</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>problem</td>\n",
       "      <td>we</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136627</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>arguments</td>\n",
       "      <td>people</td>\n",
       "      <td>do grasp come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136628</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>scientists</td>\n",
       "      <td>we</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136629</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>point</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136630</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>us</td>\n",
       "      <td>majority</td>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136631</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>Scientists</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136632</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td></td>\n",
       "      <td>they</td>\n",
       "      <td>do leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136633</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>scientist</td>\n",
       "      <td>it</td>\n",
       "      <td>do take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136634</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>number</td>\n",
       "      <td>we</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136635</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>difference</td>\n",
       "      <td>we</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136636</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>problems</td>\n",
       "      <td>they</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136637</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>time</td>\n",
       "      <td>it</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136638</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>plan</td>\n",
       "      <td>constituents</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136639</th>\n",
       "      <td>AU</td>\n",
       "      <td>./data/AU/AU10_18.html</td>\n",
       "      <td>Council</td>\n",
       "      <td>hats</td>\n",
       "      <td>Rim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136640 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country                   filename       object       subject  \\\n",
       "0           CH      ./data/CH/CH2_38.html     networks        vision   \n",
       "1           CH      ./data/CH/CH2_38.html                    regions   \n",
       "2           CH      ./data/CH/CH2_38.html                probability   \n",
       "3           CH      ./data/CH/CH2_38.html       series    situations   \n",
       "4           CH      ./data/CH/CH2_38.html    framework         Goals   \n",
       "5           CH      ./data/CH/CH2_38.html                        key   \n",
       "6           CH      ./data/CH/CH2_38.html                       they   \n",
       "7           CH      ./data/CH/CH2_38.html         part    management   \n",
       "8           CH      ./data/CH/CH2_38.html    conflicts   communities   \n",
       "9           CH      ./data/CH/CH2_38.html                       they   \n",
       "10          CH      ./data/CH/CH2_38.html        stage     Conflicts   \n",
       "11          CH      ./data/CH/CH2_38.html                       they   \n",
       "12          CH      ./data/CH/CH2_38.html                  Dialogues   \n",
       "13          CH      ./data/CH/CH2_38.html       causes       parties   \n",
       "14          CH      ./data/CH/CH2_38.html       access         cause   \n",
       "15          CH      ./data/CH/CH2_38.html      changes       effects   \n",
       "16          CH      ./data/CH/CH2_38.html                 mitigation   \n",
       "17          CH      ./data/CH/CH2_38.html      aspects     attention   \n",
       "18          CH      ./data/CH/CH2_38.html                  potential   \n",
       "19          CH      ./data/CH/CH2_38.html  cooperation     Institute   \n",
       "20          CH      ./data/CH/CH2_38.html                         it   \n",
       "21          CH      ./data/CH/CH2_38.html                      Goals   \n",
       "22          CH      ./data/CH/CH2_38.html  discussions     Dialogues   \n",
       "23          CH      ./data/CH/CH2_38.html                  Dialogues   \n",
       "24          CH      ./data/CH/CH2_38.html     Director         Veres   \n",
       "25          CH      ./data/CH/CH2_38.html     director         Brahm   \n",
       "26          UK       ./data/UK/UK6_7.html                         It   \n",
       "27          UK       ./data/UK/UK6_7.html      Islands          Sura   \n",
       "28          UK       ./data/UK/UK6_7.html     enormity           she   \n",
       "29          UK       ./data/UK/UK6_7.html                        she   \n",
       "...        ...                        ...          ...           ...   \n",
       "136610      ME  ./data/ME/ME7.1 (44).html        plans             ’   \n",
       "136611      ME  ./data/ME/ME7.1 (44).html       Center            We   \n",
       "136612      ME  ./data/ME/ME7.1 (44).html                         It   \n",
       "136613      ME  ./data/ME/ME7.1 (44).html                         we   \n",
       "136614      ME  ./data/ME/ME7.1 (44).html       cranes            we   \n",
       "136615      ME  ./data/ME/ME7.1 (44).html                         we   \n",
       "136616      AU     ./data/AU/AU10_18.html                    Council   \n",
       "136617      AU     ./data/AU/AU10_18.html  discussions       council   \n",
       "136618      AU     ./data/AU/AU10_18.html                      steps   \n",
       "136619      AU     ./data/AU/AU10_18.html     response        debate   \n",
       "136620      AU     ./data/AU/AU10_18.html                 objections   \n",
       "136621      AU     ./data/AU/AU10_18.html                         it   \n",
       "136622      AU     ./data/AU/AU10_18.html                   sceptics   \n",
       "136623      AU     ./data/AU/AU10_18.html                         we   \n",
       "136624      AU     ./data/AU/AU10_18.html                    nothing   \n",
       "136625      AU     ./data/AU/AU10_18.html    pollution          they   \n",
       "136626      AU     ./data/AU/AU10_18.html      problem            we   \n",
       "136627      AU     ./data/AU/AU10_18.html    arguments        people   \n",
       "136628      AU     ./data/AU/AU10_18.html   scientists            we   \n",
       "136629      AU     ./data/AU/AU10_18.html                      point   \n",
       "136630      AU     ./data/AU/AU10_18.html           us      majority   \n",
       "136631      AU     ./data/AU/AU10_18.html                 Scientists   \n",
       "136632      AU     ./data/AU/AU10_18.html                       they   \n",
       "136633      AU     ./data/AU/AU10_18.html    scientist            it   \n",
       "136634      AU     ./data/AU/AU10_18.html       number            we   \n",
       "136635      AU     ./data/AU/AU10_18.html   difference            we   \n",
       "136636      AU     ./data/AU/AU10_18.html     problems          they   \n",
       "136637      AU     ./data/AU/AU10_18.html         time            it   \n",
       "136638      AU     ./data/AU/AU10_18.html         plan  constituents   \n",
       "136639      AU     ./data/AU/AU10_18.html      Council          hats   \n",
       "\n",
       "                             verb  \n",
       "0                          evoke   \n",
       "1                        include   \n",
       "2              dismiss anticipate  \n",
       "3                  arise do occur  \n",
       "4                          serve   \n",
       "5                             be   \n",
       "6                            use   \n",
       "7                             be   \n",
       "8       resolve become exacerbate  \n",
       "9                          arise   \n",
       "10                       mitigate  \n",
       "11                      escalate   \n",
       "12                          help   \n",
       "13                          find   \n",
       "14                            be   \n",
       "15                         cause   \n",
       "16                            be   \n",
       "17                            be   \n",
       "18                        prevent  \n",
       "19                         enter   \n",
       "20                       promote   \n",
       "21                                 \n",
       "22          promote build sustain  \n",
       "23                           aim   \n",
       "24                            be   \n",
       "25                            be   \n",
       "26                            be   \n",
       "27                           fly   \n",
       "28                    appreciate   \n",
       "29                           take  \n",
       "...                           ...  \n",
       "136610                         s   \n",
       "136611                open target  \n",
       "136612                        be   \n",
       "136613                             \n",
       "136614                      need   \n",
       "136615                       set   \n",
       "136616                        be   \n",
       "136617                    benefit  \n",
       "136618                        be   \n",
       "136619                   dominate  \n",
       "136620                             \n",
       "136621                        be   \n",
       "136622                      need   \n",
       "136623                        do   \n",
       "136624                      mean   \n",
       "136625                're support  \n",
       "136626                       face  \n",
       "136627              do grasp come  \n",
       "136628                        be   \n",
       "136629                        be   \n",
       "136630                       tell  \n",
       "136631                        be   \n",
       "136632                   do leave  \n",
       "136633                    do take  \n",
       "136634                       see   \n",
       "136635                      make   \n",
       "136636                             \n",
       "136637                        be   \n",
       "136638                    accept   \n",
       "136639                       Rim   \n",
       "\n",
       "[136640 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country  verb\n",
       "AU       said    12\n",
       "CH       said    14\n",
       "IN       said    12\n",
       "KE       said     1\n",
       "ME       said    12\n",
       "NG       said    15\n",
       "UK       said    10\n",
       "US       said    10\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svo_df[svo_df['verb']=='said'].groupby('country')['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       VP                                                                                                                                                                                                                      \n",
      "  _____|_______                                                                                                                                                                                                                 \n",
      " |             VP                                                                                                                                                                                                              \n",
      " |      _______|_________________                                                                                                                                                                                               \n",
      " |     |                        SBAR                                                                                                                                                                                           \n",
      " |     |                         |                                                                                                                                                                                              \n",
      " |     |                         S                                                                                                                                                                                             \n",
      " |     |              ___________|____________                                                                                                                                                                                  \n",
      " |     |             |                        VP                                                                                                                                                                               \n",
      " |     |             |            ____________|_____________                                                                                                                                                                    \n",
      " |     |             |           |                          VP                                                                                                                                                                 \n",
      " |     |             |           |       ___________________|___________________________                                                                                                                                        \n",
      " |     |             |           |      |                                              SBAR                                                                                                                                    \n",
      " |     |             |           |      |      _________________________________________|____________________________________________                                                                                           \n",
      " |     |             |           |      |     |                                                                                      S                                                                                         \n",
      " |     |             |           |      |     |         _____________________________________________________________________________|_____                                                                                     \n",
      " |     |             |           |      |     |        |                                                                                   VP                                                                                  \n",
      " |     |             |           |      |     |        |          _________________________________________________________________________|___                                                                                 \n",
      " |     |             |           |      |     |        |         |                                                                             VP                                                                              \n",
      " |     |             |           |      |     |        |         |     ________________________________________________________________________|____________________________                                                    \n",
      " |     |             |           |      |     |        |         |    |                             |                                                                      SBAR                                                \n",
      " |     |             |           |      |     |        |         |    |                             |                                 ______________________________________|____                                               \n",
      " |     |             |           |      |     |        |         |    |                             |                                |                                           S                                             \n",
      " |     |             |           |      |     |        |         |    |                             |                                |          _________________________________|____________________________                  \n",
      " |     |             |           |      |     |        |         |    |                             |                                |         PP                                               |             |                \n",
      " |     |             |           |      |     |        |         |    |                             |                                |      ___|________                                        |             |                 \n",
      " |     |             |           |      |     |        |         |    |                             |                                |     |            NP                                      |             VP               \n",
      " |     |             |           |      |     |        |         |    |                             |                                |     |        ____|____________                           |    _________|___              \n",
      " |     |             |           |      |     |        |         |    |                             NP                               |     |       |                 PP                         |   |             VP           \n",
      " |     |             |           |      |     |        |         |    |          ___________________|_____                           |     |       |           ______|______                    |   |     ________|___          \n",
      " |     |             |           |      |     |        |         |    |         |                         PP                         |     |       |          |             NP                  |   |    |            PP       \n",
      " |     |             |           |      |     |        |         |    |         |                _________|_____                     |     |       |          |       ______|________           |   |    |         ___|____     \n",
      " |     |             NP          |      |     |        NP        |    |         NP              |               NP                   |     |       NP         |      NP     |        NP         NP  |    |        |        NP  \n",
      " |     |        _____|_____      |      |     |     ___|____     |    |      ___|_______        |    ___________|____________        |     |    ___|____      |      |      |     ___|____      |   |    |        |        |    \n",
      "VBZ   VBG      NN         NNS   VBZ    VBG    IN   DT       NN  VBZ  VBG    DT          NN      IN  CD    JJ   NNP    NN     NN      IN    IN  DT       NN    IN     NN     CC   DT       NN   PRP VBZ  VBG       TO       NN  \n",
      " |     |       |           |     |      |     |    |        |    |    |     |           |       |   |     |     |     |      |       |     |   |        |     |      |      |    |        |     |   |    |        |        |    \n",
      " s  leading climate     experts  is  warning that the     world  is facing the     catastrophe  of  “  runaway  ”  climate change because  of the     impact  of pollution and  the     damage  it  is doing      to     nature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_df[sampled_df['filename']=='./data/UK/UK1_23.html'].parse_sents[5511][7][0][0][2].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verb         country\n",
       "be           US         1356\n",
       "             ME         1248\n",
       "             CH         1077\n",
       "             IN          932\n",
       "             AU          771\n",
       "             NG          691\n",
       "say          US          631\n",
       "be           UK          587\n",
       "             KE          514\n",
       "say          CH          513\n",
       "             ME          487\n",
       "s            ME          354\n",
       "say          IN          352\n",
       "             NG          346\n",
       "             UK          327\n",
       "             AU          291\n",
       "             US          271\n",
       "             ME          248\n",
       "have         US          206\n",
       "             CH          201\n",
       "say          KE          198\n",
       "have         CH          196\n",
       "             ME          195\n",
       "             IN          186\n",
       "have         NG          172\n",
       "             NG          164\n",
       "s            US          159\n",
       "'s           US          148\n",
       "have         AU          142\n",
       "             IN          141\n",
       "                        ... \n",
       "turf         AU            1\n",
       "lag          AU            1\n",
       "last         AU            1\n",
       "lag          AU            1\n",
       "             NG            1\n",
       "lag set      CH            1\n",
       "lambast      ME            1\n",
       "lament       CH            1\n",
       "lament       ME            1\n",
       "lament call  AU            1\n",
       "land         CH            1\n",
       "land         ME            1\n",
       "             NG            1\n",
       "lap swallow  UK            1\n",
       "lash         IN            1\n",
       "last         KE            1\n",
       "launch       NG            1\n",
       "last         ME            1\n",
       "             US            1\n",
       "laud         IN            1\n",
       "             NG            1\n",
       "laud         CH            1\n",
       "             IN            1\n",
       "             NG            1\n",
       "             US            1\n",
       "laugh        CH            1\n",
       "             ME            1\n",
       "             UK            1\n",
       "launch       AU            1\n",
       "…            ME            1\n",
       "Name: country, Length: 10786, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svo_df.groupby(by=['verb']).country.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_df.to_pickle('svo_simplified.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
